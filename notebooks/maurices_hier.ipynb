{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vyper.user import Model\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from vyper.user.explorer import DataProfiler\n",
    "from openpyxl import Workbook\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from vyper.utils.tools import StatisticalTools as st\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import scipy as stats\n",
    "from scipy.stats import chi2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from varclushi import VarClusHi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "from k_means_constrained import KMeansConstrained\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from kneed import KneeLocator\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from matplotlib.cm import viridis\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class Hierarchical:\n",
    "    def __init__(self, data):\n",
    "        self.df = pd.read_csv(data)\n",
    "        # self.df = self.df.iloc[:20000, :]\n",
    "\n",
    "    def get_shape(self):\n",
    "        return self.df.shape\n",
    "\n",
    "    def get_df(self):\n",
    "        return self.df\n",
    "\n",
    "    def dendogram(self):\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.title(\"Dendogram\")\n",
    "        shc.dendrogram(shc.linkage(self.df, method='ward'))\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def silhouette(estimator, df, metric='euclidean'):\n",
    "        # print(self.df.shape)\n",
    "        labels = estimator.fit_predict(df)\n",
    "        score = silhouette_score(df, labels, metric=metric)\n",
    "        return score\n",
    "\n",
    "    # def create_folds(self, n):\n",
    "    #     df_folds = self.df.copy()\n",
    "    #     df_folds[\"fold\"] = np.random.randint(1, n + 1, size=len(self.df))\n",
    "    #     return df_folds\n",
    "\n",
    "    # def nfold(self, folded_data, estimator, n):\n",
    "    #     #randomly assign folds to the df\n",
    "    #     # df_folds = self.df.copy()\n",
    "    #     # df_folds[\"fold\"] = np.random.randint(1, n + 1, size=len(self.df))\n",
    "    #     score = 0\n",
    "    #     #select one fold and use the rest folds as input for modeling\n",
    "    #     for i in range(1, n + 1):\n",
    "    #         # self.df = df_folds[df_folds.fold != i].copy()\n",
    "    #         # self.df.drop(\"fold\", axis=1, inplace=True)\n",
    "    #         sil = self.silhouette(estimator, folded_data[folded_data.fold != i].drop(['fold'], axis=1),\n",
    "    #                               metric='euclidean')\n",
    "    #         score += sil\n",
    "    #     score = score / n\n",
    "    #     return score\n",
    "\n",
    "    # def gridSearchCV_hierarchical(self, grid, cv=5):\n",
    "    #     score_max = 0\n",
    "    #     linkage = n_clusters = affinity = None\n",
    "    #     fd = self.create_folds(cv)\n",
    "    #     training_history = {'score':[], 'n_clusters': [], 'linkage': [], 'affinity': []}\n",
    "    #     # self.training_history = {}\n",
    "    #     for n in grid[\"n_clusters\"]:\n",
    "    #         for l in grid[\"linkage\"]:\n",
    "    #             for a in grid[\"affinity\"]:\n",
    "    #                 if l == \"ward\" and a != \"euclidean\":\n",
    "    #                     continue\n",
    "    #                 else:\n",
    "    #                     hierarchical = AgglomerativeClustering(n_clusters=n, affinity=a, linkage=l)\n",
    "    #                     score = self.nfold(fd, hierarchical, cv)\n",
    "    #                     training_history['score'].append(score)\n",
    "    #                     training_history['n_clusters'].append(n)\n",
    "    #                     training_history['linkage'].append(l)\n",
    "    #                     training_history['affinity'].append(a)\n",
    "    #                     # print(\"score:\", score, \" n_clusters:\", n, \" linkage:\", l, \" affinity:\", a)\n",
    "    #                     if score > score_max:\n",
    "    #                         score_max = score\n",
    "    #                         linkage = l\n",
    "    #                         affinity = a\n",
    "    #                         n_clusters = n\n",
    "    #     return score_max, n_clusters, linkage, affinity, training_history\n",
    "\n",
    "    @staticmethod\n",
    "    def get_training_history(training_history):\n",
    "        return pd.DataFrame.from_dict(training_history)\n",
    "\n",
    "\n",
    "\n",
    "    # def gridSearchCV_hierarchical(self, grid, cv=5, n_jobs=-1, verbose=0):\n",
    "    #     score_max = 0\n",
    "    #     linkage = n_clusters = affinity = None\n",
    "    #     fd = self.create_folds(cv)\n",
    "    #     training_history = {'score':[], 'n_clusters': [], 'linkage': [], 'affinity': []}\n",
    "    #     param_combinations = [(n, l, a) for n in grid['n_clusters'] for l in grid['linkage'] for a in grid['affinity'] if not (l == 'ward' and a != 'euclidean')]\n",
    "    #     if verbose:\n",
    "    #         print(f'Number of combinations to test: {len(param_combinations)}')\n",
    "    #     scores = Parallel(n_jobs=n_jobs)(delayed(self._fit_hierarchical)(n, l, a, fd,cv) for n, l, a in param_combinations)\n",
    "    #     for i, score in enumerate(scores):\n",
    "    #         n, l, a = param_combinations[i]\n",
    "    #         training_history['score'].append(score)\n",
    "    #         training_history['n_clusters'].append(n)\n",
    "    #         training_history['linkage'].append(l)\n",
    "    #         training_history['affinity'].append(a)\n",
    "    #         if score > score_max:\n",
    "    #             score_max = score\n",
    "    #             linkage = l\n",
    "    #             affinity = a\n",
    "    #             n_clusters = n\n",
    "    #     return score_max, n_clusters, linkage, affinity, training_history\n",
    "    #\n",
    "    # def _fit_hierarchical(self, n_clusters, linkage, affinity, fd,cv):\n",
    "    #     hierarchical = AgglomerativeClustering(n_clusters=n_clusters, affinity=affinity, linkage=linkage)\n",
    "    #     score = self.nfold(fd, hierarchical,cv)\n",
    "    #     return score\n",
    "    # def gridSearchCV_hierarchical(self, grid, cv=5):\n",
    "    #     score_max = 0\n",
    "    #     linkage = n_clusters = affinity = None\n",
    "    #     fd = self.create_folds(cv)\n",
    "    #     training_history = {'score':[], 'n_clusters': [], 'linkage': [], 'affinity': []}\n",
    "    #\n",
    "    #     def run_hierarchical(n, l, a):\n",
    "    #         if l == \"ward\" and a != \"euclidean\":\n",
    "    #             return None\n",
    "    #         hierarchical = AgglomerativeClustering(n_clusters=n, affinity=a, linkage=l)\n",
    "    #         score = self.nfold(fd, hierarchical, cv)\n",
    "    #         return score, n, l, a\n",
    "    #\n",
    "    #     num_cores = multiprocessing.cpu_count()\n",
    "    #     print(\"Number of cores:\", num_cores)\n",
    "    #     results = Parallel(n_jobs=num_cores)(\n",
    "    #         delayed(run_hierarchical)(n, l, a) for n in grid[\"n_clusters\"]\n",
    "    #                                           for l in grid[\"linkage\"]\n",
    "    #                                           for a in grid[\"affinity\"]\n",
    "    #     )\n",
    "    #\n",
    "    #     for result in results:\n",
    "    #         if result is not None and result[0] > score_max:\n",
    "    #             score_max, n_clusters, linkage, affinity = result[0], result[1], result[2], result[3]\n",
    "    #         if result is not None:\n",
    "    #             training_history['score'].append(result[0])\n",
    "    #             training_history['n_clusters'].append(result[1])\n",
    "    #             training_history['linkage'].append(result[2])\n",
    "    #             training_history['affinity'].append(result[3])\n",
    "    #\n",
    "    #     return score_max, n_clusters, linkage, affinity, training_history\n",
    "\n",
    "\n",
    "\n",
    "    def gridSearchCV_hierarchical(self, grid, cv=5):\n",
    "        # fd = self.create_folds(cv)\n",
    "        hierarchical = AgglomerativeClustering()\n",
    "        grid_search = GridSearchCV(estimator=hierarchical, param_grid=grid, cv=cv, scoring=self.silhouette)\n",
    "        grid_search.fit(self.df)\n",
    "        training_history = grid_search.cv_results_\n",
    "        return grid_search.best_score_, grid_search.best_params_, training_history\n",
    "\n",
    "    def randomizedSearchCV_hierarchical(self, grid, cv=5, n_iter=10,rand_sample_prop=0.2):\n",
    "        # fd = self.create_folds(cv)\n",
    "        sample_data = self.df.sample(frac=rand_sample_prop)\n",
    "        hierarchical = AgglomerativeClustering()\n",
    "        random_search = RandomizedSearchCV(estimator=hierarchical, param_distributions=grid, cv=cv, scoring=self.silhouette, n_iter=n_iter)\n",
    "        random_search.fit(sample_data)\n",
    "        training_history = random_search.cv_results_\n",
    "        return random_search.best_score_, random_search.best_params_, training_history"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "folds = 5\n",
    "params_grid = {\"linkage\": [\"ward\", \"complete\", \"average\", \"single\"],\n",
    "               \"n_clusters\": list(range(2, 10)),\n",
    "               \"affinity\": [\"euclidean\", \"l1\", \"l2\", \"manhattan\", \"cosine\"]}\n",
    "# params_grid = {\"linkage\": [\"complete\", \"average\", \"single\"],\n",
    "#                \"n_clusters\": list(range(2, 10)),\n",
    "#                \"affinity\": [\"euclidean\", \"manhattan\", \"cosine\"]}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "hi = Hierarchical('maurices_oc_preprocessed.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(99942, 13)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi.get_shape()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 333.2494750022888 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "a, b, c = hi.randomizedSearchCV_hierarchical(params_grid, folds)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "score_max, n_clusters, linkage, affinity = a, b['n_clusters'], b['linkage'], b['affinity']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "{'mean_fit_time': array([1.06222529e+01, 9.73192034e+00, 1.00706166e+01, 3.01735048e+00,\n        2.81138420e-03, 2.28419304e-03, 1.57216191e+00, 1.00420602e+01,\n        1.60499477e+00, 1.05856113e+01]),\n 'std_fit_time': array([5.22299703e-01, 2.19574825e-01, 2.48395323e-01, 1.24097444e-01,\n        7.46487671e-04, 3.93809517e-04, 2.51387340e-02, 7.53241747e-02,\n        3.56634499e-02, 1.22780201e+00]),\n 'mean_score_time': array([0.76795197, 0.67951565, 0.73575082, 0.45559478, 0.        ,\n        0.        , 0.35424495, 0.72591538, 0.34792509, 0.82168465]),\n 'std_score_time': array([0.04472238, 0.00942883, 0.05044203, 0.01786562, 0.        ,\n        0.        , 0.00628541, 0.03478234, 0.00612616, 0.14825182]),\n 'param_n_clusters': masked_array(data=[8, 7, 7, 3, 5, 3, 8, 2, 4, 2],\n              mask=[False, False, False, False, False, False, False, False,\n                    False, False],\n        fill_value='?',\n             dtype=object),\n 'param_linkage': masked_array(data=['complete', 'average', 'complete', 'single', 'ward',\n                    'ward', 'single', 'complete', 'single', 'ward'],\n              mask=[False, False, False, False, False, False, False, False,\n                    False, False],\n        fill_value='?',\n             dtype=object),\n 'param_affinity': masked_array(data=['manhattan', 'l2', 'l1', 'cosine', 'l2', 'cosine',\n                    'l1', 'l1', 'manhattan', 'euclidean'],\n              mask=[False, False, False, False, False, False, False, False,\n                    False, False],\n        fill_value='?',\n             dtype=object),\n 'params': [{'n_clusters': 8, 'linkage': 'complete', 'affinity': 'manhattan'},\n  {'n_clusters': 7, 'linkage': 'average', 'affinity': 'l2'},\n  {'n_clusters': 7, 'linkage': 'complete', 'affinity': 'l1'},\n  {'n_clusters': 3, 'linkage': 'single', 'affinity': 'cosine'},\n  {'n_clusters': 5, 'linkage': 'ward', 'affinity': 'l2'},\n  {'n_clusters': 3, 'linkage': 'ward', 'affinity': 'cosine'},\n  {'n_clusters': 8, 'linkage': 'single', 'affinity': 'l1'},\n  {'n_clusters': 2, 'linkage': 'complete', 'affinity': 'l1'},\n  {'n_clusters': 4, 'linkage': 'single', 'affinity': 'manhattan'},\n  {'n_clusters': 2, 'linkage': 'ward', 'affinity': 'euclidean'}],\n 'split0_test_score': array([ 0.56828246,  0.65542179,  0.57061714, -0.33980733,         nan,\n                nan,  0.65354698,  0.73865356,  0.69000613,  0.66099093]),\n 'split1_test_score': array([ 0.5012712 ,  0.65365063,  0.56800793, -0.30617817,         nan,\n                nan,  0.63832709,  0.72871474,  0.64675843,  0.69719627]),\n 'split2_test_score': array([ 0.5228533 ,  0.63238634,  0.52112153, -0.22225184,         nan,\n                nan,  0.59700733,  0.71114232,  0.61274127,  0.57042663]),\n 'split3_test_score': array([ 0.52966692,  0.6544435 ,  0.55719576, -0.15295294,         nan,\n                nan,  0.59650482,  0.71549872,  0.62555406,  0.56071337]),\n 'split4_test_score': array([ 0.58906187,  0.63766217,  0.61859232, -0.28372398,         nan,\n                nan,  0.62118017,  0.70185878,  0.68804794,  0.64502515]),\n 'mean_test_score': array([ 0.54222715,  0.64671289,  0.56710694, -0.26098285,         nan,\n                nan,  0.62131328,  0.71917362,  0.65262157,  0.62687047]),\n 'std_test_score': array([0.03188374, 0.00970469, 0.03123065, 0.06624746,        nan,\n               nan, 0.0225155 , 0.01302545, 0.03165469, 0.05291916]),\n 'rank_test_score': array([7, 3, 6, 8, 9, 9, 5, 1, 2, 4])}"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7191736249351095"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n0      10.622253      0.522300         0.767952        0.044722   \n1       9.731920      0.219575         0.679516        0.009429   \n2      10.070617      0.248395         0.735751        0.050442   \n3       3.017350      0.124097         0.455595        0.017866   \n4       0.002811      0.000746         0.000000        0.000000   \n5       0.002284      0.000394         0.000000        0.000000   \n6       1.572162      0.025139         0.354245        0.006285   \n7      10.042060      0.075324         0.725915        0.034782   \n8       1.604995      0.035663         0.347925        0.006126   \n9      10.585611      1.227802         0.821685        0.148252   \n\n  param_n_clusters param_linkage param_affinity  \\\n0                8      complete      manhattan   \n1                7       average             l2   \n2                7      complete             l1   \n3                3        single         cosine   \n4                5          ward             l2   \n5                3          ward         cosine   \n6                8        single             l1   \n7                2      complete             l1   \n8                4        single      manhattan   \n9                2          ward      euclidean   \n\n                                              params  split0_test_score  \\\n0  {'n_clusters': 8, 'linkage': 'complete', 'affi...           0.568282   \n1  {'n_clusters': 7, 'linkage': 'average', 'affin...           0.655422   \n2  {'n_clusters': 7, 'linkage': 'complete', 'affi...           0.570617   \n3  {'n_clusters': 3, 'linkage': 'single', 'affini...          -0.339807   \n4  {'n_clusters': 5, 'linkage': 'ward', 'affinity...                NaN   \n5  {'n_clusters': 3, 'linkage': 'ward', 'affinity...                NaN   \n6  {'n_clusters': 8, 'linkage': 'single', 'affini...           0.653547   \n7  {'n_clusters': 2, 'linkage': 'complete', 'affi...           0.738654   \n8  {'n_clusters': 4, 'linkage': 'single', 'affini...           0.690006   \n9  {'n_clusters': 2, 'linkage': 'ward', 'affinity...           0.660991   \n\n   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n0           0.501271           0.522853           0.529667           0.589062   \n1           0.653651           0.632386           0.654444           0.637662   \n2           0.568008           0.521122           0.557196           0.618592   \n3          -0.306178          -0.222252          -0.152953          -0.283724   \n4                NaN                NaN                NaN                NaN   \n5                NaN                NaN                NaN                NaN   \n6           0.638327           0.597007           0.596505           0.621180   \n7           0.728715           0.711142           0.715499           0.701859   \n8           0.646758           0.612741           0.625554           0.688048   \n9           0.697196           0.570427           0.560713           0.645025   \n\n   mean_test_score  std_test_score  rank_test_score  \n0         0.542227        0.031884                7  \n1         0.646713        0.009705                3  \n2         0.567107        0.031231                6  \n3        -0.260983        0.066247                8  \n4              NaN             NaN                9  \n5              NaN             NaN                9  \n6         0.621313        0.022515                5  \n7         0.719174        0.013025                1  \n8         0.652622        0.031655                2  \n9         0.626870        0.052919                4  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_n_clusters</th>\n      <th>param_linkage</th>\n      <th>param_affinity</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10.622253</td>\n      <td>0.522300</td>\n      <td>0.767952</td>\n      <td>0.044722</td>\n      <td>8</td>\n      <td>complete</td>\n      <td>manhattan</td>\n      <td>{'n_clusters': 8, 'linkage': 'complete', 'affi...</td>\n      <td>0.568282</td>\n      <td>0.501271</td>\n      <td>0.522853</td>\n      <td>0.529667</td>\n      <td>0.589062</td>\n      <td>0.542227</td>\n      <td>0.031884</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9.731920</td>\n      <td>0.219575</td>\n      <td>0.679516</td>\n      <td>0.009429</td>\n      <td>7</td>\n      <td>average</td>\n      <td>l2</td>\n      <td>{'n_clusters': 7, 'linkage': 'average', 'affin...</td>\n      <td>0.655422</td>\n      <td>0.653651</td>\n      <td>0.632386</td>\n      <td>0.654444</td>\n      <td>0.637662</td>\n      <td>0.646713</td>\n      <td>0.009705</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10.070617</td>\n      <td>0.248395</td>\n      <td>0.735751</td>\n      <td>0.050442</td>\n      <td>7</td>\n      <td>complete</td>\n      <td>l1</td>\n      <td>{'n_clusters': 7, 'linkage': 'complete', 'affi...</td>\n      <td>0.570617</td>\n      <td>0.568008</td>\n      <td>0.521122</td>\n      <td>0.557196</td>\n      <td>0.618592</td>\n      <td>0.567107</td>\n      <td>0.031231</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.017350</td>\n      <td>0.124097</td>\n      <td>0.455595</td>\n      <td>0.017866</td>\n      <td>3</td>\n      <td>single</td>\n      <td>cosine</td>\n      <td>{'n_clusters': 3, 'linkage': 'single', 'affini...</td>\n      <td>-0.339807</td>\n      <td>-0.306178</td>\n      <td>-0.222252</td>\n      <td>-0.152953</td>\n      <td>-0.283724</td>\n      <td>-0.260983</td>\n      <td>0.066247</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.002811</td>\n      <td>0.000746</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5</td>\n      <td>ward</td>\n      <td>l2</td>\n      <td>{'n_clusters': 5, 'linkage': 'ward', 'affinity...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.002284</td>\n      <td>0.000394</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3</td>\n      <td>ward</td>\n      <td>cosine</td>\n      <td>{'n_clusters': 3, 'linkage': 'ward', 'affinity...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.572162</td>\n      <td>0.025139</td>\n      <td>0.354245</td>\n      <td>0.006285</td>\n      <td>8</td>\n      <td>single</td>\n      <td>l1</td>\n      <td>{'n_clusters': 8, 'linkage': 'single', 'affini...</td>\n      <td>0.653547</td>\n      <td>0.638327</td>\n      <td>0.597007</td>\n      <td>0.596505</td>\n      <td>0.621180</td>\n      <td>0.621313</td>\n      <td>0.022515</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>10.042060</td>\n      <td>0.075324</td>\n      <td>0.725915</td>\n      <td>0.034782</td>\n      <td>2</td>\n      <td>complete</td>\n      <td>l1</td>\n      <td>{'n_clusters': 2, 'linkage': 'complete', 'affi...</td>\n      <td>0.738654</td>\n      <td>0.728715</td>\n      <td>0.711142</td>\n      <td>0.715499</td>\n      <td>0.701859</td>\n      <td>0.719174</td>\n      <td>0.013025</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.604995</td>\n      <td>0.035663</td>\n      <td>0.347925</td>\n      <td>0.006126</td>\n      <td>4</td>\n      <td>single</td>\n      <td>manhattan</td>\n      <td>{'n_clusters': 4, 'linkage': 'single', 'affini...</td>\n      <td>0.690006</td>\n      <td>0.646758</td>\n      <td>0.612741</td>\n      <td>0.625554</td>\n      <td>0.688048</td>\n      <td>0.652622</td>\n      <td>0.031655</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10.585611</td>\n      <td>1.227802</td>\n      <td>0.821685</td>\n      <td>0.148252</td>\n      <td>2</td>\n      <td>ward</td>\n      <td>euclidean</td>\n      <td>{'n_clusters': 2, 'linkage': 'ward', 'affinity...</td>\n      <td>0.660991</td>\n      <td>0.697196</td>\n      <td>0.570427</td>\n      <td>0.560713</td>\n      <td>0.645025</td>\n      <td>0.626870</td>\n      <td>0.052919</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi.get_training_history(c)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# n_clusters, linkage, affinity = 5, 'ward', 'l2'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_max: 0.7191736249351095  n_clusters: 2  linkage: complete  affinity: l1\n"
     ]
    }
   ],
   "source": [
    "print(\"score_max:\", score_max, \" n_clusters:\", n_clusters, \" linkage:\", linkage, \" affinity:\", affinity)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 37.2 GiB for an array with shape (4994151711,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m hierarchical \u001B[38;5;241m=\u001B[39m AgglomerativeClustering(n_clusters\u001B[38;5;241m=\u001B[39mn_clusters, linkage\u001B[38;5;241m=\u001B[39mlinkage, affinity\u001B[38;5;241m=\u001B[39maffinity)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Determine which clusters each data point belongs to:\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m clusters_hierarchical \u001B[38;5;241m=\u001B[39m \u001B[43mhierarchical\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_df\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Add cluster labels to the original data\u001B[39;00m\n\u001B[0;32m      9\u001B[0m clusters_hierarchical \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(clusters_hierarchical, columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcluster\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\cluster\\_agglomerative.py:1099\u001B[0m, in \u001B[0;36mAgglomerativeClustering.fit_predict\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m   1078\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit_predict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   1079\u001B[0m     \u001B[38;5;124;03m\"\"\"Fit and return the result of each sample's clustering assignment.\u001B[39;00m\n\u001B[0;32m   1080\u001B[0m \n\u001B[0;32m   1081\u001B[0m \u001B[38;5;124;03m    In addition to fitting, this method also return the result of the\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1097\u001B[0m \u001B[38;5;124;03m        Cluster labels.\u001B[39;00m\n\u001B[0;32m   1098\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1099\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py:734\u001B[0m, in \u001B[0;36mClusterMixin.fit_predict\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    716\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    717\u001B[0m \u001B[38;5;124;03mPerform clustering on `X` and returns cluster labels.\u001B[39;00m\n\u001B[0;32m    718\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    730\u001B[0m \u001B[38;5;124;03m    Cluster labels.\u001B[39;00m\n\u001B[0;32m    731\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    732\u001B[0m \u001B[38;5;66;03m# non-optimized default implementation; override when a better\u001B[39;00m\n\u001B[0;32m    733\u001B[0m \u001B[38;5;66;03m# method is possible for a given clustering algorithm\u001B[39;00m\n\u001B[1;32m--> 734\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    735\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabels_\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\cluster\\_agglomerative.py:956\u001B[0m, in \u001B[0;36mAgglomerativeClustering.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    954\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m    955\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(X, ensure_min_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m--> 956\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\cluster\\_agglomerative.py:1046\u001B[0m, in \u001B[0;36mAgglomerativeClustering._fit\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m   1042\u001B[0m distance_threshold \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistance_threshold\n\u001B[0;32m   1044\u001B[0m return_distance \u001B[38;5;241m=\u001B[39m (distance_threshold \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_distances\n\u001B[1;32m-> 1046\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mmemory\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcache\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtree_builder\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1047\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1048\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconnectivity\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconnectivity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1049\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_clusters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_clusters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1050\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_distance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_distance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1051\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1052\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1053\u001B[0m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren_, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_connected_components_, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_leaves_, parents) \u001B[38;5;241m=\u001B[39m out[\n\u001B[0;32m   1054\u001B[0m     :\u001B[38;5;241m4\u001B[39m\n\u001B[0;32m   1055\u001B[0m ]\n\u001B[0;32m   1057\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_distance:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\vyp\\lib\\site-packages\\joblib\\memory.py:349\u001B[0m, in \u001B[0;36mNotMemorizedFunc.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    348\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 349\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\cluster\\_agglomerative.py:665\u001B[0m, in \u001B[0;36m_complete_linkage\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    663\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_complete_linkage\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    664\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlinkage\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcomplete\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 665\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlinkage_tree\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\cluster\\_agglomerative.py:544\u001B[0m, in \u001B[0;36mlinkage_tree\u001B[1;34m(X, connectivity, n_clusters, linkage, affinity, return_distance)\u001B[0m\n\u001B[0;32m    542\u001B[0m     out \u001B[38;5;241m=\u001B[39m _hierarchical\u001B[38;5;241m.\u001B[39msingle_linkage_label(mst)\n\u001B[0;32m    543\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 544\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mhierarchy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinkage\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlinkage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maffinity\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    545\u001B[0m children_ \u001B[38;5;241m=\u001B[39m out[:, :\u001B[38;5;241m2\u001B[39m]\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    547\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_distance:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\vyp\\lib\\site-packages\\scipy\\cluster\\hierarchy.py:1060\u001B[0m, in \u001B[0;36mlinkage\u001B[1;34m(y, method, metric, optimal_ordering)\u001B[0m\n\u001B[0;32m   1056\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39mall(y \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m np\u001B[38;5;241m.\u001B[39mallclose(y, y\u001B[38;5;241m.\u001B[39mT):\n\u001B[0;32m   1057\u001B[0m             _warning(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe symmetric non-negative hollow observation \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   1058\u001B[0m                      \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmatrix looks suspiciously like an uncondensed \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   1059\u001B[0m                      \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdistance matrix\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m-> 1060\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mdistance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpdist\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1061\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1062\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`y` must be 1 or 2 dimensional.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\vyp\\lib\\site-packages\\scipy\\spatial\\distance.py:2023\u001B[0m, in \u001B[0;36mpdist\u001B[1;34m(X, metric, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2021\u001B[0m out \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mout\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m   2022\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m out \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 2023\u001B[0m     dm \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mempty\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mm\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mm\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdouble\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2024\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2025\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m out\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m!=\u001B[39m (m \u001B[38;5;241m*\u001B[39m (m \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m,):\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 37.2 GiB for an array with shape (4994151711,) and data type float64"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "hierarchical = AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage, affinity=affinity)\n",
    "\n",
    "# Determine which clusters each data point belongs to:\n",
    "clusters_hierarchical = hierarchical.fit_predict(hi.get_df()) + 1\n",
    "\n",
    "# Add cluster labels to the original data\n",
    "clusters_hierarchical = pd.DataFrame(clusters_hierarchical, columns=['cluster'])\n",
    "df_reduced = pd.concat([hi.get_df(), clusters_hierarchical], axis=1)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cluster=df_reduced['cluster']\n",
    "df_reduced.drop(labels=['cluster'], axis=1,inplace = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(df_reduced)\n",
    "principalComponents = pd.DataFrame(data=principalComponents, index=df_reduced.index, columns=['PC1', 'PC2'])\n",
    "principalComponents['cluster'] = cluster"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(principalComponents['PC1'], principalComponents['PC2'], c=principalComponents['cluster'],cmap=viridis)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cluster.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
